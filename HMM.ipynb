{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything in this notebook is from https://www.pymc.io/projects/examples/en/latest/case_studies/wrapping_jax_function.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "import pytensor\n",
    "import pytensor.tensor as pt\n",
    "import pandas as pd\n",
    "from pytensor.graph import Apply, Op\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.scipy as jsp\n",
    "import pymc.sampling_jax\n",
    "import seaborn as sns\n",
    "import scipy as sp \n",
    "from pytensor.link.jax.dispatch import jax_funcify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 104109109\n",
    "rng = np.random.default_rng(RANDOM_SEED)\n",
    "az.style.use(\"arviz-darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emission signal and noise parameters\n",
    "emission_signal_true = 1.15\n",
    "emission_noise_true = 0.15\n",
    "\n",
    "p_initial_state_true = np.array([0.9, 0.09, 0.01])\n",
    "\n",
    "# Probability of switching from state_t to state_t+1\n",
    "p_transition_true = np.array(\n",
    "    [\n",
    "        #    0,   1,   2\n",
    "        [0.9, 0.09, 0.01],  # 0\n",
    "        [0.1, 0.8, 0.1],  # 1\n",
    "        [0.2, 0.1, 0.7],  # 2\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Confirm that we have defined valid probabilities\n",
    "assert np.isclose(np.sum(p_initial_state_true), 1)\n",
    "assert np.allclose(np.sum(p_transition_true, axis=-1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compute the log of the probalitiy transition matrix for later use\n",
    "with np.errstate(divide=\"ignore\"):\n",
    "    logp_initial_state_true = np.log(p_initial_state_true)\n",
    "    logp_transition_true = np.log(p_transition_true)\n",
    "\n",
    "logp_initial_state_true, logp_transition_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will observe 70 HMM processes, each with a total of 50 steps\n",
    "n_obs = 70\n",
    "n_steps = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_hmm(p_initial_state, p_transition, emission_signal, emission_noise, n_steps, rng):\n",
    "    \"\"\"Generate hidden state and emission from our HMM model.\"\"\"\n",
    "\n",
    "    possible_states = np.array([0, 1, 2])\n",
    "\n",
    "    hidden_states = []\n",
    "    initial_state = rng.choice(possible_states, p=p_initial_state)\n",
    "    hidden_states.append(initial_state)\n",
    "    for step in range(n_steps):\n",
    "        new_hidden_state = rng.choice(possible_states, p=p_transition[hidden_states[-1]])\n",
    "        hidden_states.append(new_hidden_state)\n",
    "    hidden_states = np.array(hidden_states)\n",
    "\n",
    "    emissions = rng.normal(\n",
    "        (hidden_states + 1) * emission_signal,\n",
    "        emission_noise,\n",
    "    )\n",
    "\n",
    "    return hidden_states, emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_hmm_hidden_state, single_hmm_emission = simulate_hmm(\n",
    "    p_initial_state_true,\n",
    "    p_transition_true,\n",
    "    emission_signal_true,\n",
    "    emission_noise_true,\n",
    "    n_steps,\n",
    "    rng,\n",
    ")\n",
    "print(single_hmm_hidden_state)\n",
    "print(np.round(single_hmm_emission, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_state_true = []\n",
    "emission_observed = []\n",
    "\n",
    "for i in range(n_obs):\n",
    "    hidden_state, emission = simulate_hmm(\n",
    "        p_initial_state_true,\n",
    "        p_transition_true,\n",
    "        emission_signal_true,\n",
    "        emission_noise_true,\n",
    "        n_steps,\n",
    "        rng,\n",
    "    )\n",
    "    hidden_state_true.append(hidden_state)\n",
    "    emission_observed.append(emission)\n",
    "\n",
    "hidden_state = np.array(hidden_state_true)\n",
    "emission_observed = np.array(emission_observed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, figsize=(8, 6), sharex=True)\n",
    "# Plot first five hmm processes\n",
    "for i in range(4):\n",
    "    ax[0].plot(hidden_state_true[i] + i * 0.02, color=f\"C{i}\", lw=2, alpha=0.4)\n",
    "    ax[1].plot(emission_observed[i], color=f\"C{i}\", lw=2, alpha=0.4)\n",
    "ax[0].set_yticks([0, 1, 2])\n",
    "ax[0].set_ylabel(\"hidden state\")\n",
    "ax[1].set_ylabel(\"observed emmission\")\n",
    "ax[1].set_xlabel(\"step\")\n",
    "fig.suptitle(\"Simulated data\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hmm_logp(\n",
    "    emission_observed,\n",
    "    emission_signal,\n",
    "    emission_noise,\n",
    "    logp_initial_state,\n",
    "    logp_transition,\n",
    "):\n",
    "    \"\"\"Compute the marginal log-likelihood of a single HMM process.\"\"\"\n",
    "\n",
    "    hidden_states = np.array([0, 1, 2])\n",
    "\n",
    "    # Compute log-likelihood of observed emissions for each (step x possible hidden state)\n",
    "    logp_emission = jsp.stats.norm.logpdf(\n",
    "        emission_observed[:, None],\n",
    "        (hidden_states + 1) * emission_signal,\n",
    "        emission_noise,\n",
    "    )\n",
    "\n",
    "    # We use the forward_algorithm to compute log_alpha(x_t) = logp(x_t, y_1:t)\n",
    "    log_alpha = logp_initial_state + logp_emission[0]\n",
    "    log_alpha, _ = jax.lax.scan(\n",
    "        f=lambda log_alpha_prev, logp_emission: (\n",
    "            jsp.special.logsumexp(log_alpha_prev + logp_transition.T, axis=-1) + logp_emission,\n",
    "            None,\n",
    "        ),\n",
    "        init=log_alpha,\n",
    "        xs=logp_emission[1:],\n",
    "    )\n",
    "\n",
    "    return jsp.special.logsumexp(log_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm_logp(\n",
    "    emission_observed[0],\n",
    "    emission_signal_true,\n",
    "    emission_noise_true,\n",
    "    logp_initial_state_true,\n",
    "    logp_transition_true,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_hmm_logp(*args):\n",
    "    vmap = jax.vmap(\n",
    "        hmm_logp,\n",
    "        # Only the first argument, needs to be vectorized\n",
    "        in_axes=(0, None, None, None, None),\n",
    "    )\n",
    "    # For simplicity we sum across all the HMM processes\n",
    "    return jnp.sum(vmap(*args))\n",
    "\n",
    "\n",
    "# We jit it for better performance!\n",
    "jitted_vec_hmm_logp = jax.jit(vec_hmm_logp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jitted_vec_hmm_logp(\n",
    "    emission_observed[0][None, :],\n",
    "    emission_signal_true,\n",
    "    emission_noise_true,\n",
    "    logp_initial_state_true,\n",
    "    logp_transition_true,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jitted_vec_hmm_logp(\n",
    "    emission_observed,\n",
    "    emission_signal_true,\n",
    "    emission_noise_true,\n",
    "    logp_initial_state_true,\n",
    "    logp_transition_true,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jitted_vec_hmm_logp_grad = jax.jit(jax.grad(vec_hmm_logp, argnums=list(range(5))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jitted_vec_hmm_logp_grad(\n",
    "    emission_observed,\n",
    "    emission_signal_true,\n",
    "    emission_noise_true,\n",
    "    logp_initial_state_true,\n",
    "    logp_transition_true,\n",
    ")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMMLogpOp(Op):\n",
    "    def make_node(\n",
    "        self,\n",
    "        emission_observed,\n",
    "        emission_signal,\n",
    "        emission_noise,\n",
    "        logp_initial_state,\n",
    "        logp_transition,\n",
    "    ):\n",
    "        # Convert our inputs to symbolic variables\n",
    "        inputs = [\n",
    "            pt.as_tensor_variable(emission_observed),\n",
    "            pt.as_tensor_variable(emission_signal),\n",
    "            pt.as_tensor_variable(emission_noise),\n",
    "            pt.as_tensor_variable(logp_initial_state),\n",
    "            pt.as_tensor_variable(logp_transition),\n",
    "        ]\n",
    "        # Define the type of the output returned by the wrapped JAX function\n",
    "        outputs = [pt.dscalar()]\n",
    "        return Apply(self, inputs, outputs)\n",
    "\n",
    "    def perform(self, node, inputs, outputs):\n",
    "        result = jitted_vec_hmm_logp(*inputs)\n",
    "        # PyTensor raises an error if the dtype of the returned output is not\n",
    "        # exactly the one expected from the Apply node (in this case\n",
    "        # `dscalar`, which stands for float64 scalar), so we make sure\n",
    "        # to convert to the expected dtype. To avoid unnecessary conversions\n",
    "        # you should make sure the expected output defined in `make_node`\n",
    "        # is already of the correct dtype\n",
    "        outputs[0][0] = np.asarray(result, dtype=node.outputs[0].dtype)\n",
    "\n",
    "    def grad(self, inputs, output_gradients):\n",
    "        (\n",
    "            grad_wrt_emission_obsered,\n",
    "            grad_wrt_emission_signal,\n",
    "            grad_wrt_emission_noise,\n",
    "            grad_wrt_logp_initial_state,\n",
    "            grad_wrt_logp_transition,\n",
    "        ) = hmm_logp_grad_op(*inputs)\n",
    "        # If there are inputs for which the gradients will never be needed or cannot\n",
    "        # be computed, `pytensor.gradient.grad_not_implemented` should  be used as the\n",
    "        # output gradient for that input.\n",
    "        output_gradient = output_gradients[0]\n",
    "        return [\n",
    "            output_gradient * grad_wrt_emission_obsered,\n",
    "            output_gradient * grad_wrt_emission_signal,\n",
    "            output_gradient * grad_wrt_emission_noise,\n",
    "            output_gradient * grad_wrt_logp_initial_state,\n",
    "            output_gradient * grad_wrt_logp_transition,\n",
    "        ]\n",
    "\n",
    "\n",
    "class HMMLogpGradOp(Op):\n",
    "    def make_node(\n",
    "        self,\n",
    "        emission_observed,\n",
    "        emission_signal,\n",
    "        emission_noise,\n",
    "        logp_initial_state,\n",
    "        logp_transition,\n",
    "    ):\n",
    "        inputs = [\n",
    "            pt.as_tensor_variable(emission_observed),\n",
    "            pt.as_tensor_variable(emission_signal),\n",
    "            pt.as_tensor_variable(emission_noise),\n",
    "            pt.as_tensor_variable(logp_initial_state),\n",
    "            pt.as_tensor_variable(logp_transition),\n",
    "        ]\n",
    "        # This `Op` will return one gradient per input. For simplicity, we assume\n",
    "        # each output is of the same type as the input. In practice, you should use\n",
    "        # the exact dtype to avoid overhead when saving the results of the computation\n",
    "        # in `perform`\n",
    "        outputs = [inp.type() for inp in inputs]\n",
    "        return Apply(self, inputs, outputs)\n",
    "\n",
    "    def perform(self, node, inputs, outputs):\n",
    "        (\n",
    "            grad_wrt_emission_obsered_result,\n",
    "            grad_wrt_emission_signal_result,\n",
    "            grad_wrt_emission_noise_result,\n",
    "            grad_wrt_logp_initial_state_result,\n",
    "            grad_wrt_logp_transition_result,\n",
    "        ) = jitted_vec_hmm_logp_grad(*inputs)\n",
    "        outputs[0][0] = np.asarray(grad_wrt_emission_obsered_result, dtype=node.outputs[0].dtype)\n",
    "        outputs[1][0] = np.asarray(grad_wrt_emission_signal_result, dtype=node.outputs[1].dtype)\n",
    "        outputs[2][0] = np.asarray(grad_wrt_emission_noise_result, dtype=node.outputs[2].dtype)\n",
    "        outputs[3][0] = np.asarray(grad_wrt_logp_initial_state_result, dtype=node.outputs[3].dtype)\n",
    "        outputs[4][0] = np.asarray(grad_wrt_logp_transition_result, dtype=node.outputs[4].dtype)\n",
    "\n",
    "\n",
    "# Initialize our `Op`s\n",
    "hmm_logp_op = HMMLogpOp()\n",
    "hmm_logp_grad_op = HMMLogpGradOp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm_logp_op(\n",
    "    emission_observed,\n",
    "    emission_signal_true,\n",
    "    emission_noise_true,\n",
    "    logp_initial_state_true,\n",
    "    logp_transition_true,\n",
    ").eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm_logp_grad_op(\n",
    "    emission_observed,\n",
    "    emission_signal_true,\n",
    "    emission_noise_true,\n",
    "    logp_initial_state_true,\n",
    "    logp_transition_true,\n",
    ")[1].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define the symbolic `emission_signal` variable outside of the `Op`\n",
    "# so that we can request the gradient wrt to it\n",
    "emission_signal_variable = pt.as_tensor_variable(emission_signal_true)\n",
    "x = hmm_logp_op(\n",
    "    emission_observed,\n",
    "    emission_signal_variable,\n",
    "    emission_noise_true,\n",
    "    logp_initial_state_true,\n",
    "    logp_transition_true,\n",
    ")\n",
    "x_grad_wrt_emission_signal = pt.grad(x, wrt=emission_signal_variable)\n",
    "x_grad_wrt_emission_signal.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model:\n",
    "    emission_signal = pm.Normal(\"emission_signal\", 0, 1)\n",
    "    emission_noise = pm.HalfNormal(\"emission_noise\", 1)\n",
    "\n",
    "    p_initial_state = pm.Dirichlet(\"p_initial_state\", np.ones(3))\n",
    "    logp_initial_state = pt.log(p_initial_state)\n",
    "\n",
    "    p_transition = pm.Dirichlet(\"p_transition\", np.ones(3), size=3)\n",
    "    logp_transition = pt.log(p_transition)\n",
    "\n",
    "    loglike = pm.Potential(\n",
    "        \"hmm_loglike\",\n",
    "        hmm_logp_op(\n",
    "            emission_observed,\n",
    "            emission_signal,\n",
    "            emission_noise,\n",
    "            logp_initial_state,\n",
    "            logp_transition,\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.model_to_graphviz(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute_initial_point() is not working, maybe need new function name\n",
    "#initial_point = model.compute_initial_point()\n",
    "#initial_point\n",
    "#model.point_logps(initial_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#but sampling is working\n",
    "with model:\n",
    "    idata = pm.sample(chains=2, cores=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(idata);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_values = [\n",
    "    emission_signal_true,\n",
    "    emission_noise_true,\n",
    "    *p_initial_state_true,\n",
    "    *p_transition_true.ravel(),\n",
    "]\n",
    "\n",
    "az.plot_posterior(idata, ref_val=true_values, grid=(3, 5));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
